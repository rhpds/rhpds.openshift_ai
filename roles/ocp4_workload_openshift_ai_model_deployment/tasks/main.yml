---
- name: Create amespace for hosting model
  kubernetes.core.k8s:
    state: present
    api_version: v1
    kind: Namespace
    name: "{{ ocp4_workload_openshift_ai_model_deployment_namespace }}"

- name: Get cluster ingress config
  kubernetes.core.k8s_info:
    api_version: config.openshift.io/v1
    kind: Ingress
    name: cluster
  register: r_ingress_config
  until: r_ingress_config.resources is defined
  retries: 10
  delay: 30

- name: Set ingress domain
  ansible.builtin.set_fact:
    _ocp4_workload_openshift_ai_model_deployment_ingress_domain: "{{ r_ingress_config.resources[0].spec.domain }}"

- name: Create Inference Gateway Resources
  kubernetes.core.k8s:
    template: "{{ item }}"
  loop:
  - inference-gateway-class.yaml.j2
  - inference-gateway.yaml.j2

- name: Create Model Deployment
  kubernetes.core.k8s:
    template: "{{ item }}"
    namespace: "{{ ocp4_workload_openshift_ai_model_deployment_namespace }}"
  loop:
  - llama-32-3b-instruct-secret.yaml.j2
  - llama-32-3b-instruct-serving-runtime.yaml.j2
  - llama-32-3b-instruct-inference-service.yaml.j2
  - llama-32-3b-instruct-http-route.yaml.j2

- name: Save user data
  agnosticd.core.agnosticd_user_info:
    data:
      llama_32_3b_instruct_endpoint: "https://inference-gateway.{{ _ocp4_workload_openshift_ai_model_deployment_ingress_domain }}/llama-32-3b-instruct"

- name: Print Admin credentials
  agnosticd.core.agnosticd_user_info:
    msg: "{{ item }}"
  loop:
  - "Llama inference endpoint: https://inference-gateway.{{ _ocp4_workload_openshift_ai_model_deployment_ingress_domain }}/llama-32-3b-instruct"

- name: LLM Endpoint Test
  agnosticd.core.agnosticd_user_info:
    msg: |
      Test the LLM endpoint with a simple curl request:

      curl https://inference-gateway.{{ _ocp4_workload_openshift_ai_model_deployment_ingress_domain }}/llama-32-3b-instruct/v1/completions \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer YOUR_API_KEY" \
        -H "X-Model: llama-32-3b-instruct" \
        -d '{
          "model": "llama-32-3b-instruct",
          "prompt": "Write a short greeting message:",
          "max_tokens": 100,
          "temperature": 0.7
        }'
