---
ocp4_workload_openshift_ai_model_as_a_service_helm_repo: https://github.com/treddy08/model-as-a-service.git
ocp4_workload_openshift_ai_model_as_a_service_helm_repo_target_revision: main
ocp4_workload_openshift_ai_model_as_a_service_maas_username: maas-user
ocp4_workload_openshift_ai_model_as_a_service_api_users:
  [
    {% for i in range(1,5) %}
    {
      "username": "api-user-{{ i }}",
      "apiKey": "{{ lookup('password', '/dev/null length=20 chars=ascii_letters,digits') }}",
      "tier": "tier-free-users"
    },
    {% endfor %}
  ]
ocp4_workload_openshift_ai_model_as_a_service_models:
- apiVersion: serving.kserve.io/v1alpha1
  kind: LLMInferenceService
  metadata:
    name: single-node-no-scheduler-cpu
    namespace: llm
    annotations:
      alpha.maas.opendatahub.io/tiers: '[]'
      argocd.argoproj.io/sync-wave: "2"
  spec:
    model:
      uri: hf://facebook/opt-125m
      name: facebook/opt-125m
    replicas: 1
    router:
      route: { }
      # Connect to MaaS-enabled gateway
      gateway:
        refs:
          - name: maas-default-gateway
            namespace: openshift-ingress
    template:
      containers:
        - name: main
          image: quay.io/pierdipi/vllm-cpu:latest
          env:
            - name: VLLM_LOGGING_LEVEL
              value: INFO
          resources:
            limits:
              cpu: '2'
              memory: 10Gi
            requests:
              cpu: '100m'
              memory: 8Gi
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
              scheme: HTTPS
            initialDelaySeconds: 90
            periodSeconds: 30
            timeoutSeconds: 30
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
              scheme: HTTPS
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 30
- apiVersion: serving.kserve.io/v1alpha1
  kind: LLMInferenceService
  metadata:
    name: granite-8b-code-instruct
    namespace: llm
    annotations:
      openshift.io/display-name: granite-8b-code-instruct
      alpha.maas.opendatahub.io/tiers: '[]'
      argocd.argoproj.io/sync-wave: "2"
    labels:
      opendatahub.io/dashboard: 'true'
  spec:
    model:
      name: granite-8b-code-instruct
      uri: 'oci://registry.redhat.io/rhelai1/modelcar-granite-8b-code-instruct:1.4'
    replicas: 1
    router:
      route: { }
      # Connect to MaaS-enabled gateway
      gateway:
        refs:
          - name: maas-default-gateway
            namespace: openshift-ingress
    template:
      # Ensure the pod is scheduled on GPU nodes
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - effect: NoSchedule
          key: nvidia.com/gpu
          operator: Exists
      containers:
      - name: main
        resources:
          limits:
            cpu: '2'
            memory: 12Gi
            nvidia.com/gpu: '1'
          requests:
            cpu: '500m'
            memory: 8Gi
            nvidia.com/gpu: '1'